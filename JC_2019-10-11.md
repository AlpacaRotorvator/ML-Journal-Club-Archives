# ML Journal Club
2nd Edition ⁠— 2019-10-11

---

## General Discussion

### [NGBoost: Natural Gradient Boosting for Probabilistic Prediction](https://arxiv.org/abs/1910.03225)
**Presented by**: Daniel Vargas

**Authors**: Tony Duan, Anand Avati, Daisy Yi Ding, Sanjay Basu, Andrew Y. Ng, Alejandro Schuler

**DOI**: N/A

**Abstract**: We present Natural Gradient Boosting (NGBoost), an algorithm which brings probabilistic prediction capability to gradient boosting in a generic way. Predictive uncertainty estimation is crucial in many applications such as healthcare and weather forecasting. Probabilistic prediction, which is the approach where the model outputs a full probability distribution over the entire outcome space, is a natural way to quantify those uncertainties. Gradient Boosting Machines have been widely successful in prediction tasks on structured input data, but a simple boosting solution for probabilistic prediction of real valued outputs is yet to be made. NGBoost is a gradient boosting approach which uses the \emph{Natural Gradient} to address technical challenges that makes generic probabilistic prediction hard with existing gradient boosting methods. Our approach is modular with respect to the choice of base learner, probability distribution, and scoring rule. We show empirically on several regression datasets that NGBoost provides competitive predictive performance of both uncertainty estimates and traditional metrics. 

### The Model Thinker
**Presented by**: Victor Geraldo

*Soon*

### [Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches](https://arxiv.org/abs/1907.06902v3)
**Presented by**: Brian K.

**Authors**: Maurizio Ferrari Dacrema, Paolo Cremonesi, Dietmar Jannach

**DOI**: [10.1145/3298689.3347058](https://dx.doi.org/10.1145/3298689.3347058)

**Abstract**: Deep learning techniques have become the method of choice for researchers working on algorithmic aspects of recommender systems. With the strongly increased interest in machine learning in general, it has, as a result, become difficult to keep track of what represents the state-of-the-art at the moment, e.g., for top-n recommendation tasks. At the same time, several recent publications point out problems in today's research practice in applied machine learning, e.g., in terms of the reproducibility of the results or the choice of the baselines when proposing new models. In this work, we report the results of a systematic analysis of algorithmic proposals for top-n recommendation tasks. Specifically, we considered 18 algorithms that were presented at top-level research conferences in the last years. Only 7 of them could be reproduced with reasonable effort. For these methods, it however turned out that 6 of them can often be outperformed with comparably simple heuristic methods, e.g., based on nearest-neighbor or graph-based techniques. The remaining one clearly outperformed the baselines but did not consistently outperform a well-tuned non-neural linear ranking method. Overall, our work sheds light on a number of potential problems in today's machine learning scholarship and calls for improved scientific practices in this area. Source code of our experiments and full results are available at: [this https URL](https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation). 

### [Random walks in recommender systems: exact computation and simulations](http://wwwconference.org/proceedings/www2014/companion/p811.pdf)
**Presented by**: Brian K.

**Authors**: C Cooper, SH Lee, T Radzik, Y Siantos

**DOI**: [10.1145/2567948.2579244](http://dx.doi.org/10.1145/2567948.2579244)

**Abstract**: A recommender system uses information about known associations between users and items to compute for a given user an ordered recommendation list of items which this user might be interested in acquiring. We consider ordering rules based on various parameters of random walks on the graph representing associations between users and items. We experimentally compare the quality of recommendations and the required computational resources of two approaches: (i) calculate the exact values of the relevant random walk parameters using matrix algebra; (ii) estimate these values by simulating random walks. In our experiments we include methods proposed by Fouss et al. and Gori and Pucci, method P3, which is based on the distribution of the random walk after three steps, and method P3a, which generalises P3. We show that the simple method P3 can outperform previous methods and method P3a can offer further improvements. We show that the time- and memory-efficiency of direct simulation of random walks allows application of these methods to large datasets. We use in our experiments the three MovieLens datasets.

---

## Featured Paper
**Speaker**: Brian K.

### [Efficient Reinforcement Learning Through Evolving Neural Network Topologies](http://nn.cs.utexas.edu/downloads/papers/stanley.gecco02_1.pdf)
**DOI**: [10.1109/CEC.2002.1004508](https://doi.org/10.1109/CEC.2002.1004508)

**Authors**: Kenneth O. Stanley, Risto Miikkulainen 

**Abstract**: Neuroevolution, i.e. evolving artificial neural networks with genetic algorithms, has been highly effective in reinforcement learning tasks, particularly those with hidden state information. An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, NeuroEvolution of Augmenting Topologies (NEAT) that outperforms the best fixed-topology methods on a challenging benchmark reinforcement learning task. We claim that the increased efficiency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incrementally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is significantly faster learning. NEAT is also an important contribution to GAs because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, making it possible to evolve increasingly complex solutions over time, thereby strengthening the analogy with biological evolution.

**Obs.**: See also [Evolving Neural Networks through Augmenting Topologies](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf) from the same authors for a more in-depth discussion of neuroevolutionary approaches to reinforcement learning, the difficulties involved, how NEAT tackles them and why it works.